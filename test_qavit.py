"""
Comprehensive test script for QAViT
Validates all dimensions and mathematical correctness for CVPR submission
"""

import os
os.environ['CUDA_VISIBLE_DEVICES'] = ''  # Use CPU only for testing

import torch
import torch.nn as nn
from QAViT import (
    qavit_tiny, qavit_small,
    QAViTConfig,
    create_model_and_dataloaders,
    DATASET_CONFIGS
)

def test_dimension_flow():
    """Test dimension flow through all components"""
    print("="*80)
    print("DIMENSION VALIDATION TEST")
    print("="*80)
    
    # Test configurations
    configs = {
        'tiny': QAViTConfig(
            img_size=224,
            patch_size=16,
            embed_dim=256,
            depth=2,  # Reduced for quick testing
            num_heads=4,
            num_classes=100
        ),
        'small': QAViTConfig(
            img_size=224,
            patch_size=16,
            embed_dim=384,
            depth=2,  # Reduced for quick testing
            num_heads=6,
            num_classes=100
        )
    }
    
    for name, config in configs.items():
        print(f"\n{'='*80}")
        print(f"Testing QAViT-{name.upper()}")
        print(f"{'='*80}")
        
        # Print config
        print(f"Config:")
        print(f"  embed_dim (d): {config.embed_dim}")
        print(f"  d' (compressed): {config.embed_dim // config.compress_ratio}")
        print(f"  r (bottleneck): {config.embed_dim // config.bottleneck_ratio}")
        print(f"  num_heads: {config.num_heads}")
        print(f"  head_dim: {config.embed_dim // config.num_heads}")
        print(f"  num_channel_groups: {config.num_channel_groups}")
        print(f"  channels_per_group: {config.embed_dim // config.num_channel_groups}")
        
        # Create model
        if name == 'tiny':
            model = qavit_tiny(num_classes=config.num_classes, depth=config.depth)
        else:
            model = qavit_small(num_classes=config.num_classes, depth=config.depth)
        
        model.eval()
        
        # Test input
        batch_size = 2
        x = torch.randn(batch_size, 3, config.img_size, config.img_size)
        
        print(f"\nInput shape: {x.shape}")
        
        try:
            # Forward pass
            with torch.no_grad():
                output = model(x)
            
            print(f"Output shape: {output.shape}")
            print(f"Expected: ({batch_size}, {config.num_classes})")
            
            # Verify output shape
            assert output.shape == (batch_size, config.num_classes), \
                f"Output shape mismatch! Got {output.shape}, expected ({batch_size}, {config.num_classes})"
            
            print(f"‚úÖ PASS: {name.upper()} dimension flow correct!")
            
            # Count parameters
            num_params = sum(p.numel() for p in model.parameters())
            print(f"Total parameters: {num_params:,}")
            
        except Exception as e:
            print(f"‚ùå FAIL: {name.upper()} test failed!")
            print(f"Error: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    return True


def test_individual_components():
    """Test each component individually"""
    print("\n" + "="*80)
    print("COMPONENT-WISE VALIDATION TEST")
    print("="*80)
    
    config = QAViTConfig(
        img_size=224,
        patch_size=16,
        embed_dim=256,
        num_heads=4,
        num_classes=100,
        depth=1
    )
    
    B, N, C = 2, 196, 256  # batch=2, patches=196 (14x14), channels=256
    
    from QAViT import (
        GlobalTokenBank,
        EfficientSpatialWindowAttention,
        EfficientMultiScaleDilatedAttention,
        EfficientChannelGroupAttention,
        CrossAttentionBranch,
        HybridFusion,
        BottleneckMLP,
        CCFFFN,
        QuadAttentionBlock
    )
    
    tests = []
    
    # Test Global Token Bank
    print("\n1. Testing Global Token Bank...")
    try:
        bank = GlobalTokenBank(config.global_bank_size, config.embed_dim)
        k_bank, v_bank = bank.read(B)
        assert k_bank.shape == (B, config.global_bank_size, config.embed_dim)
        assert v_bank.shape == (B, config.global_bank_size, config.embed_dim)
        tokens = torch.randn(B, N, C)
        bank.write(tokens)
        print(f"   ‚úÖ Global Token Bank: PASS")
        tests.append(True)
    except Exception as e:
        print(f"   ‚ùå Global Token Bank: FAIL - {str(e)}")
        tests.append(False)
    
    # Test SWA
    print("\n2. Testing Spatial Window Attention (SWA)...")
    try:
        bank = GlobalTokenBank(config.global_bank_size, config.embed_dim)
        swa = EfficientSpatialWindowAttention(config, bank)
        x = torch.randn(B, N, C)
        out = swa(x)
        assert out.shape == (B, N, C), f"SWA output shape {out.shape} != expected {(B, N, C)}"
        print(f"   ‚úÖ SWA: PASS")
        tests.append(True)
    except Exception as e:
        print(f"   ‚ùå SWA: FAIL - {str(e)}")
        import traceback
        traceback.print_exc()
        tests.append(False)
    
    # Test MSDA
    print("\n3. Testing Multi-Scale Dilated Attention (MSDA)...")
    try:
        bank = GlobalTokenBank(config.global_bank_size, config.embed_dim)
        msda = EfficientMultiScaleDilatedAttention(config, bank)
        x = torch.randn(B, N, C)
        out = msda(x)
        assert out.shape == (B, N, C), f"MSDA output shape {out.shape} != expected {(B, N, C)}"
        print(f"   ‚úÖ MSDA: PASS")
        tests.append(True)
    except Exception as e:
        print(f"   ‚ùå MSDA: FAIL - {str(e)}")
        import traceback
        traceback.print_exc()
        tests.append(False)
    
    # Test CGA
    print("\n4. Testing Channel Group Attention (CGA)...")
    try:
        bank = GlobalTokenBank(config.global_bank_size, config.embed_dim)
        cga = EfficientChannelGroupAttention(config, bank)
        x = torch.randn(B, N, C)
        out = cga(x)
        assert out.shape == (B, N, C), f"CGA output shape {out.shape} != expected {(B, N, C)}"
        print(f"   ‚úÖ CGA: PASS")
        tests.append(True)
    except Exception as e:
        print(f"   ‚ùå CGA: FAIL - {str(e)}")
        import traceback
        traceback.print_exc()
        tests.append(False)
    
    # Test Cross-Attention
    print("\n5. Testing Cross-Attention Branch...")
    try:
        bank = GlobalTokenBank(config.global_bank_size, config.embed_dim)
        cross = CrossAttentionBranch(config, bank)
        x = torch.randn(B, N, C)
        out = cross(x)
        assert out.shape == (B, N, C), f"Cross-Attn output shape {out.shape} != expected {(B, N, C)}"
        print(f"   ‚úÖ Cross-Attention: PASS")
        tests.append(True)
    except Exception as e:
        print(f"   ‚ùå Cross-Attention: FAIL - {str(e)}")
        tests.append(False)
    
    # Test Hybrid Fusion
    print("\n6. Testing Hybrid Fusion...")
    try:
        d_prime = config.embed_dim // config.compress_ratio
        fusion = HybridFusion(d_prime, num_branches=4)
        branches = [torch.randn(B, N, d_prime) for _ in range(4)]
        out = fusion(branches)
        assert out.shape == (B, N, 4 * d_prime), f"Fusion output shape {out.shape} != expected {(B, N, 4 * d_prime)}"
        print(f"   ‚úÖ Hybrid Fusion: PASS")
        tests.append(True)
    except Exception as e:
        print(f"   ‚ùå Hybrid Fusion: FAIL - {str(e)}")
        tests.append(False)
    
    # Test Bottleneck MLP
    print("\n7. Testing Bottleneck MLP...")
    try:
        d_prime = config.embed_dim // config.compress_ratio
        r = config.embed_dim // config.bottleneck_ratio
        mlp = BottleneckMLP(4 * d_prime, r, config.embed_dim)
        x = torch.randn(B, N, 4 * d_prime)
        out = mlp(x)
        assert out.shape == (B, N, config.embed_dim), f"MLP output shape {out.shape} != expected {(B, N, config.embed_dim)}"
        print(f"   ‚úÖ Bottleneck MLP: PASS")
        tests.append(True)
    except Exception as e:
        print(f"   ‚ùå Bottleneck MLP: FAIL - {str(e)}")
        tests.append(False)
    
    # Test CCF-FFN
    print("\n8. Testing CCF-FFN...")
    try:
        ffn = CCFFFN(config.embed_dim, mlp_ratio=config.mlp_ratio)
        x = torch.randn(B, N, C)
        out = ffn(x)
        assert out.shape == (B, N, C), f"FFN output shape {out.shape} != expected {(B, N, C)}"
        print(f"   ‚úÖ CCF-FFN: PASS")
        tests.append(True)
    except Exception as e:
        print(f"   ‚ùå CCF-FFN: FAIL - {str(e)}")
        tests.append(False)
    
    # Test Quad-Attention Block
    print("\n9. Testing Quad-Attention Block...")
    try:
        bank = GlobalTokenBank(config.global_bank_size, config.embed_dim)
        block = QuadAttentionBlock(config, bank, drop_path=0.0)
        x = torch.randn(B, N, C)
        out = block(x)
        assert out.shape == (B, N, C), f"Block output shape {out.shape} != expected {(B, N, C)}"
        print(f"   ‚úÖ Quad-Attention Block: PASS")
        tests.append(True)
    except Exception as e:
        print(f"   ‚ùå Quad-Attention Block: FAIL - {str(e)}")
        import traceback
        traceback.print_exc()
        tests.append(False)
    
    print("\n" + "="*80)
    print(f"Component Tests: {sum(tests)}/{len(tests)} passed")
    print("="*80)
    
    return all(tests)


def test_mathematical_properties():
    """Test mathematical properties and invariants"""
    print("\n" + "="*80)
    print("MATHEMATICAL PROPERTIES VALIDATION")
    print("="*80)
    
    config = QAViTConfig(
        img_size=224,
        patch_size=16,
        embed_dim=256,
        num_heads=4,
        num_classes=100,
        depth=2
    )
    
    model = qavit_tiny(num_classes=100, depth=2)
    model.eval()
    
    B, C, H, W = 2, 3, 224, 224
    x = torch.randn(B, C, H, W)
    
    print("\n1. Testing output consistency...")
    with torch.no_grad():
        out1 = model(x)
        out2 = model(x)
    
    # Outputs should be identical in eval mode
    assert torch.allclose(out1, out2, atol=1e-6), "Model not deterministic in eval mode!"
    print("   ‚úÖ Output consistency: PASS")
    
    print("\n2. Testing gradient flow...")
    model.train()
    x.requires_grad = True
    out = model(x)
    loss = out.sum()
    loss.backward()
    
    # Check if gradients exist
    assert x.grad is not None, "No gradient for input!"
    print("   ‚úÖ Gradient flow: PASS")
    
    print("\n3. Testing batch independence...")
    model.eval()
    with torch.no_grad():
        x_single = x[0:1]
        out_single = model(x_single)
        out_batch = model(x)
        
        # First sample from batch should match single forward
        assert torch.allclose(out_single, out_batch[0:1], atol=1e-5), \
            "Batch processing not independent!"
    print("   ‚úÖ Batch independence: PASS")
    
    print("\n4. Verifying architectural constraints...")
    # d' = d/4
    d = config.embed_dim
    d_prime = d // config.compress_ratio
    assert d_prime == d // 4, f"d' constraint violated: {d_prime} != {d//4}"
    print(f"   ‚úÖ d' = d/4: {d_prime} = {d}/4")
    
    # r = d/2
    r = d // config.bottleneck_ratio
    assert r == d // 2, f"r constraint violated: {r} != {d//2}"
    print(f"   ‚úÖ r = d/2: {r} = {d}/2")
    
    # Verify dimensions in Quad-Attention Block
    block = model.blocks[0]
    assert block.compressed_dim == d_prime, f"Compressed dim mismatch in block"
    print(f"   ‚úÖ Block compressed_dim = d': {block.compressed_dim} = {d_prime}")
    
    print("\n" + "="*80)
    print("All mathematical properties validated!")
    print("="*80)
    
    return True


def test_cifar100_setup():
    """Test CIFAR-100 setup"""
    print("\n" + "="*80)
    print("CIFAR-100 DATASET SETUP TEST")
    print("="*80)
    
    try:
        # Create model and dataloaders
        print("\nCreating QAViT-Tiny with CIFAR-100...")
        model, train_loader, val_loader, config = create_model_and_dataloaders(
            model_size='tiny',
            dataset_name='cifar100'
        )
        
        print(f"\n‚úÖ Model and dataloaders created successfully!")
        print(f"   Train batches: {len(train_loader)}")
        print(f"   Val batches: {len(val_loader)}")
        
        # Test one batch
        print("\nTesting forward pass on real batch...")
        model.eval()
        x_batch, y_batch = next(iter(train_loader))
        print(f"   Batch input shape: {x_batch.shape}")
        print(f"   Batch labels shape: {y_batch.shape}")
        
        with torch.no_grad():
            output = model(x_batch)
        
        print(f"   Batch output shape: {output.shape}")
        assert output.shape[0] == x_batch.shape[0], "Batch size mismatch!"
        assert output.shape[1] == 100, "Number of classes should be 100!"
        
        print(f"\n‚úÖ CIFAR-100 setup test PASSED!")
        return True
        
    except Exception as e:
        print(f"\n‚ùå CIFAR-100 setup test FAILED!")
        print(f"Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Run all tests"""
    print("\n" + "="*80)
    print(" "*20 + "QAViT VALIDATION SUITE")
    print(" "*15 + "CVPR Paper Architecture Verification")
    print("="*80)
    
    results = {}
    
    # Run tests
    print("\n[1/5] Running dimension flow tests...")
    results['dimension_flow'] = test_dimension_flow()
    
    print("\n[2/5] Running component-wise tests...")
    results['components'] = test_individual_components()
    
    print("\n[3/5] Running mathematical properties tests...")
    results['mathematics'] = test_mathematical_properties()
    
    print("\n[4/5] Running CIFAR-100 setup test...")
    results['cifar100'] = test_cifar100_setup()
    
    # Final summary
    print("\n" + "="*80)
    print(" "*25 + "FINAL SUMMARY")
    print("="*80)
    
    for test_name, passed in results.items():
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        print(f"{test_name.upper():.<50} {status}")
    
    all_passed = all(results.values())
    
    print("\n" + "="*80)
    if all_passed:
        print(" "*15 + "üéâ ALL TESTS PASSED! üéâ")
        print(" "*10 + "Architecture is mathematically correct")
        print(" "*12 + "Ready for CVPR paper submission!")
    else:
        print(" "*20 + "‚ö†Ô∏è  SOME TESTS FAILED")
        print(" "*15 + "Please review the errors above")
    print("="*80 + "\n")
    
    return all_passed


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
